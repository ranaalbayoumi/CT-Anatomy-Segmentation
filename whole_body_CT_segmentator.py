# -*- coding: utf-8 -*-
"""Model3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TbcV_7a5Jp0DrQgpt5ptCh2vCardQgEy
"""

# Cell 1: Install dependencies, download/unzip the dataset, and import libraries
!pip install --quiet gdown nibabel numpy scipy scikit-image matplotlib ipywidgets pyvista[all] totalsegmentator medpy itk

# Enable widgets extension (harmless if already enabled)
!jupyter nbextension enable --py widgetsnbextension || true

print("✅ Installed libraries (may have re-used cached packages).")

# Download and unzip the dataset
!gdown --id 1l6ViBkrONX5KAdziNfeB7G3AS98pb5WV
!unzip -o CT_subset_big.zip

print("✅ Downloaded and unzipped dataset.")

# Import necessary libraries
import nibabel as nib
import matplotlib.pyplot as plt
from ipywidgets import interactive, IntSlider
from IPython.display import display, clear_output, HTML
import shutil
from totalsegmentator.python_api import totalsegmentator
import os
import numpy as np
import pyvista as pv
import ipywidgets as widgets
from tqdm import tqdm
import pandas as pd
from medpy.metric.binary import hd95
from matplotlib.colors import ListedColormap
from matplotlib import cm

import nibabel as nib
import matplotlib.pyplot as plt
from ipywidgets import interactive, IntSlider
from IPython.display import display

def show_nii_slice(nii_path, slice_idx):
    img = nib.load(nii_path)
    data = img.get_fdata()
    plt.imshow(data[:, :, slice_idx], cmap='gray')
    plt.title(f'Slice {slice_idx}')
    plt.axis('off')
    plt.show()

nii_file_path = '/content/s0010/ct.nii.gz'
img = nib.load(nii_file_path)
data = img.get_fdata()
max_slices = data.shape[2] - 1

interactive_plot = interactive(
    show_nii_slice,
    nii_path=nii_file_path,
    slice_idx=IntSlider(min=0, max=max_slices, step=1, description='Slice:')
)
display(interactive_plot)

# ========= MONAI Whole Body CT Segmentation - Google Colab Version =========

# ========= 1. Install Required Packages =========
!pip install -q monai[all]
!pip install -q nibabel
!pip install -q scipy

import os
import torch
import nibabel as nib
import numpy as np
from monai.bundle import download, load
from monai.transforms import (
    LoadImage,
    EnsureChannelFirst,
    ScaleIntensity,
    Orientation,
    CropForeground,
    DivisiblePad,
    EnsureType,
    Spacing
)
from scipy import ndimage
from scipy.ndimage import binary_fill_holes, binary_opening, binary_closing

# ========= 2. Download the Model from MONAI Model Zoo =========
bundle_name = "wholeBody_ct_segmentation"

# Download the model bundle to Colab (will be saved in ~/.cache/torch/hub/bundle)
# Using 'github' source to download from MONAI Model Zoo
bundle_dir = download(name=bundle_name, source="github", progress=True)
print(f"✅ Model downloaded to: {bundle_dir}")

# ========= 3. Load Model =========
model = load(name=bundle_name, bundle_dir=bundle_dir)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()
print(f"🚀 Using device: {device}")

# ========= 4. Setup Input File Path =========
# The input file should be at /content/s0010/ct.nii.gz
input_path = "/content/s0010/ct.nii.gz"

# Check if file exists
if not os.path.exists(input_path):
    print(f"❌ File not found: {input_path}")
    print("📤 Please make sure your file is uploaded to /content/s0015/ct.nii.gz")
    print("\nYou can upload it using one of these methods:")
    print("1. Upload directly:")
    print("   !mkdir -p /content/s0015")
    print("   from google.colab import files")
    print("   uploaded = files.upload()")
    print("   !mv uploaded_file.nii.gz /content/s0015/ct.nii.gz")
    print("\n2. Or mount Google Drive:")
    print("   from google.colab import drive")
    print("   drive.mount('/content/drive')")
    print("   !cp /content/drive/MyDrive/path/to/ct.nii.gz /content/s0010/ct.nii.gz")
else:
    print(f"✅ Input file found: {input_path}")

# ========= 5. Setup Output Directory =========
output_dir = "/content/segmentation_output"
os.makedirs(output_dir, exist_ok=True)

# ========= 6. Load and Preprocess Image =========
# Load original image and store its properties
nii_original = nib.load(input_path)
original_affine = nii_original.affine
original_header = nii_original.header
original_shape = nii_original.shape
print(f"📊 Original image shape: {original_shape}")

loader = LoadImage(image_only=True)
image = loader(input_path)

# Store original image for later restoration (not needed for this approach)
# image_original = image.clone() if isinstance(image, torch.Tensor) else np.array(image)

# Track preprocessing transformations
transforms = [
    EnsureChannelFirst(),
    ScaleIntensity(),
    Orientation(axcodes="RAS"),
    CropForeground(),
    DivisiblePad(k=96),
    EnsureType()
]

# Apply preprocessing and track the crop transformation
crop_transform = None
for i, t in enumerate(transforms):
    if isinstance(t, CropForeground):
        crop_transform = t
        # Store cropping information
        image = t(image)
        cropped_shape = image.shape
    else:
        image = t(image)

print(f"📊 Preprocessed image shape: {image.shape}")

image = image.unsqueeze(0).float().to(device)

# ========= 7. Run Segmentation with Sliding Window (Memory Efficient) =========
from monai.inferers import sliding_window_inference

print("🔄 Running segmentation with sliding window inference...")
print("⚠️ This may take several minutes due to memory constraints...")

# Clear cache before inference
torch.cuda.empty_cache()

# Use CPU for output storage to save GPU memory
with torch.no_grad():
    output = sliding_window_inference(
        inputs=image,
        roi_size=(96, 96, 96),      # Process in 96x96x96 patches
        sw_batch_size=1,             # Process 1 patch at a time
        predictor=model,
        overlap=0.5,                 # 50% overlap between patches
        mode="gaussian",             # Gaussian blending for smoother results
        device=torch.device("cpu")   # Store output on CPU to save GPU memory
    )
    output = torch.argmax(output, dim=1).cpu().numpy().squeeze()

# Clear cache after inference
torch.cuda.empty_cache()

print(f"✅ Segmentation complete! Output shape: {output.shape}")

# ========= 8. Postprocessing Functions =========

def postprocess_organ_mask(mask, min_size=100):
    """
    Apply postprocessing to clean up organ segmentation masks.

    Args:
        mask: Binary mask (numpy array)
        min_size: Minimum size in voxels for connected components

    Returns:
        Cleaned binary mask
    """
    if np.sum(mask) == 0:
        return mask

    # 1. Binary closing (fill small holes and gaps)
    structure = ndimage.generate_binary_structure(3, 1)
    mask = binary_closing(mask, structure=structure, iterations=2)

    # 2. Fill holes in the mask
    mask = binary_fill_holes(mask)

    # 3. Remove small connected components
    labeled_mask, num_features = ndimage.label(mask)
    if num_features > 1:
        # Keep only components larger than min_size
        component_sizes = np.bincount(labeled_mask.ravel())
        # Find largest component (usually the actual organ)
        largest_component = component_sizes[1:].argmax() + 1
        mask = (labeled_mask == largest_component)

    # 4. Binary opening (smooth boundaries)
    mask = binary_opening(mask, structure=structure, iterations=1)

    return mask.astype(np.uint8)


def restore_original_size(segmentation, original_shape, crop_info=None):
    """
    Restore segmentation to original image size by reversing preprocessing.

    Args:
        segmentation: Segmentation output (numpy array)
        original_shape: Original image shape
        crop_info: Information about cropping (if CropForeground was used)

    Returns:
        Segmentation in original size
    """
    # Create empty array with original shape
    restored = np.zeros(original_shape, dtype=segmentation.dtype)

    # If we have crop information, place the segmentation back
    # For now, we'll use a simpler approach: resize to original shape
    from scipy.ndimage import zoom

    # Calculate zoom factors
    zoom_factors = [o / s for o, s in zip(original_shape, segmentation.shape)]

    # Resize segmentation to original shape using nearest neighbor
    # (to preserve label values)
    restored = zoom(segmentation, zoom_factors, order=0)

    return restored


# ========= 9. Restore Segmentation to Original Size =========
print("🔄 Restoring segmentation to original size...")
output_restored = restore_original_size(output, original_shape)
print(f"✅ Restored segmentation shape: {output_restored.shape}")

# ========= 10. Organ Labels Mapping =========
organ_labels = {
    1: "spleen",
    2: "kidney_right",
    3: "kidney_left",
    4: "gallbladder",
    5: "liver",
    6: "stomach",
    7: "aorta",
    8: "inferior_vena_cava",
    9: "portal_vein_and_splenic_vein",
    10: "pancreas",
    11: "adrenal_gland_right",
    12: "adrenal_gland_left",
    13: "lung_upper_lobe_left",
    14: "lung_lower_lobe_left",
    15: "lung_upper_lobe_right",
    16: "lung_middle_lobe_right",
    17: "lung_lower_lobe_right",
    18: "vertebrae_L5",
    19: "vertebrae_L4",
    20: "vertebrae_L3",
    21: "vertebrae_L2",
    22: "vertebrae_L1",
    23: "vertebrae_T12",
    24: "vertebrae_T11",
    25: "vertebrae_T10",
    26: "vertebrae_T9",
    27: "vertebrae_T8",
    28: "vertebrae_T7",
    29: "vertebrae_T6",
    30: "vertebrae_T5",
    31: "vertebrae_T4",
    32: "vertebrae_T3",
    33: "vertebrae_T2",
    34: "vertebrae_T1",
    35: "vertebrae_C7",
    36: "vertebrae_C6",
    37: "vertebrae_C5",
    38: "vertebrae_C4",
    39: "vertebrae_C3",
    40: "vertebrae_C2",
    41: "vertebrae_C1",
    42: "esophagus",
    43: "trachea",
    44: "heart_myocardium",
    45: "heart_atrium_left",
    46: "heart_ventricle_left",
    47: "heart_atrium_right",
    48: "heart_ventricle_right",
    49: "pulmonary_artery",
    50: "brain",
    51: "iliac_artery_left",
    52: "iliac_artery_right",
    53: "iliac_vena_left",
    54: "iliac_vena_right",
    55: "small_bowel",
    56: "duodenum",
    57: "colon",
    58: "rib_left_1",
    59: "rib_left_2",
    60: "rib_left_3",
    61: "rib_left_4",
    62: "rib_left_5",
    63: "rib_left_6",
    64: "rib_left_7",
    65: "rib_left_8",
    66: "rib_left_9",
    67: "rib_left_10",
    68: "rib_left_11",
    69: "rib_left_12",
    70: "rib_right_1",
    71: "rib_right_2",
    72: "rib_right_3",
    73: "rib_right_4",
    74: "rib_right_5",
    75: "rib_right_6",
    76: "rib_right_7",
    77: "rib_right_8",
    78: "rib_right_9",
    79: "rib_right_10",
    80: "rib_right_11",
    81: "rib_right_12",
    82: "humerus_left",
    83: "humerus_right",
    84: "scapula_left",
    85: "scapula_right",
    86: "clavicula_left",
    87: "clavicula_right",
    88: "femur_left",
    89: "femur_right",
    90: "hip_left",
    91: "hip_right",
    92: "sacrum",
    93: "face",
    94: "gluteus_maximus_left",
    95: "gluteus_maximus_right",
    96: "gluteus_medius_left",
    97: "gluteus_medius_right",
    98: "gluteus_minimus_left",
    99: "gluteus_minimus_right",
    100: "autochthon_left",
    101: "autochthon_right",
    102: "iliopsoas_left",
    103: "iliopsoas_right",
    104: "urinary_bladder"
}

# Define minimum sizes for different organ types (in voxels)
organ_min_sizes = {
    "liver": 5000,
    "spleen": 1000,
    "kidney": 1000,
    "lung": 5000,
    "heart": 2000,
    "brain": 5000,
    "vertebrae": 500,
    "rib": 200,
    "default": 100
}

def get_min_size(organ_name):
    """Get minimum size threshold for an organ."""
    for key, size in organ_min_sizes.items():
        if key in organ_name.lower():
            return size
    return organ_min_sizes["default"]

# ========= 11. Save Individual Organ Masks with Postprocessing =========
print("\n🔄 Applying postprocessing and saving organ masks...")

saved_count = 0
for label_id, organ_name in organ_labels.items():
    # Extract organ mask from restored segmentation
    mask = (output_restored == label_id).astype(np.uint8)

    if np.sum(mask) == 0:
        continue  # Skip empty organs

    # Apply postprocessing
    min_size = get_min_size(organ_name)
    mask_cleaned = postprocess_organ_mask(mask, min_size=min_size)

    # Skip if postprocessing removed everything (likely noise)
    if np.sum(mask_cleaned) == 0:
        print(f"⚠️  Skipped {organ_name} (removed as noise)")
        continue

    # Save with original affine and header
    seg_img = nib.Nifti1Image(mask_cleaned, original_affine, original_header)
    out_file = os.path.join(output_dir, f"{organ_name}.nii.gz")
    nib.save(seg_img, out_file)
    saved_count += 1
    print(f"✅ Saved: {organ_name}.nii.gz (shape: {mask_cleaned.shape})")

print(f"\n🎉 Segmentation complete! {saved_count} organ masks saved.")
print(f"📁 All masks are in original image size: {original_shape}")

# ========= 12. Download Results =========
from google.colab import files

# Option A: Download all files as ZIP
print("\n📦 Creating ZIP file for download...")
!zip -r segmentation_results.zip {output_dir}
files.download('segmentation_results.zip')

# Option B: Download to Google Drive (uncomment to use)
# import shutil
# drive_output = "/content/drive/MyDrive/segmentation_output"
# shutil.copytree(output_dir, drive_output)
# print(f"✅ Results copied to Google Drive: {drive_output}")

# Cell 4: 3D visualization of the segmentations

# Path to segmentations
segmentations_dir_total = "/content/segmentation_output"

# --- Organ group definitions ---
# Check which segmented files exist for ribs and update the list
rib_files_left = [f"rib_left_{i}.nii.gz" for i in range(1, 13)]
rib_files_right = [f"rib_right_{i}.nii.gz" for i in range(1, 13)]
all_rib_files = rib_files_left + rib_files_right

available_rib_files_left = [f for f in rib_files_left if os.path.exists(os.path.join(segmentations_dir_total, f))]
available_rib_files_right = [f for f in rib_files_right if os.path.exists(os.path.join(segmentations_dir_total, f))]
available_all_rib_files = available_rib_files_left + available_rib_files_right

# Added more organ groups
organ_groups = {
    "Lungs": [
        "lung_upper_lobe_left.nii.gz",
        "lung_lower_lobe_left.nii.gz",
        "lung_middle_lobe_right.nii.gz",
        "lung_upper_lobe_right.nii.gz",
        "lung_lower_lobe_right.nii.gz",
    ],
    "Vertebrae": [
        "vertebrae_L1.nii.gz", "vertebrae_L2.nii.gz", "vertebrae_L3.nii.gz",
        "vertebrae_L4.nii.gz", "vertebrae_L5.nii.gz", "vertebrae_S1.nii.gz",
        "vertebrae_T11.nii.gz", "vertebrae_T12.nii.gz"
    ],
    "Ribs (Left)": available_rib_files_left,
    "Ribs (Right)": available_rib_files_right,
    "Ribs (All)": available_all_rib_files,
    "Abdominal Organs": [
        "liver.nii.gz", "spleen.nii.gz", "kidney_left.nii.gz", "kidney_right.nii.gz",
        "gallbladder.nii.gz", "pancreas.nii.gz", "adrenal_gland_left.nii.gz",
        "adrenal_gland_right.nii.gz", "stomach.nii.gz", "small_bowel.nii.gz",
        "duodenum.nii.gz", "colon.nii.gz", "urinary_bladder.nii.gz", "prostate.nii.gz" # Added prostate
    ],
    "Heart and Veins": [
        "heart.nii.gz", "aorta.nii.gz", "inferior_vena_cava.nii.gz",
        "superior_vena_cava.nii.gz", "pulmonary_vein.nii.gz",
        "portal_vein_and_splenic_vein.nii.gz", "brachiocephalic_trunk.nii.gz",
        "brachiocephalic_vein_left.nii.gz", "brachiocephalic_vein_right.nii.gz",
        "common_carotid_artery_left.nii.gz", "common_carotid_artery_right.nii.gz",
        "subclavian_artery_left.nii.gz", "subclavian_artery_right.nii.gz",
        "iliac_artery_left.nii.gz", "iliac_artery_right.nii.gz",
        "iliac_vena_left.nii.gz", "iliac_vena_right.nii.gz"
    ],
    "Muscles": [
        "psoas_major_left.nii.gz", "psoas_major_right.nii.gz", # Added psoas_major
        "iliopsoas_left.nii.gz", "iliopsoas_right.nii.gz",
        "gluteus_maximus_left.nii.gz", "gluteus_maximus_right.nii.gz",
        "gluteus_medius_left.nii.gz", "gluteus_medius_right.nii.gz",
        "gluteus_minimus_left.nii.gz", "gluteus_minimus_right.nii.gz",
        "autochthon_left.nii.gz", "autochthon_right.nii.gz"
    ],
    "Bones": [
        "skull.nii.gz", "clavicula_left.nii.gz", "clavicula_right.nii.gz",
        "scapula_left.nii.gz", "scapula_right.nii.gz", "humerus_left.nii.gz",
        "humerus_right.nii.gz", "femur_left.nii.gz", "femur_right.nii.gz",
        "hip_left.nii.gz", "hip_right.nii.gz", "sacrum.nii.gz", "sternum.nii.gz",
        "costal_cartilages.nii.gz" # Added costal_cartilages
    ],
    "Others": [
        "spinal_cord.nii.gz", "esophagus.nii.gz", "trachea.nii.gz",
        "thyroid_gland.nii.gz", "atrial_appendage_left.nii.gz",
        "kidney_cyst_left.nii.gz", "kidney_cyst_right.nii.gz"
    ]
}

# --- UI widgets ---
organ_dropdown = widgets.Dropdown(
    options=list(organ_groups.keys()),
    description="Organ:",
    value="Lungs",
    style={'description_width': 'initial'}, # Added styling
    layout=widgets.Layout(width="auto") # Adjusted width
)

parts_select = widgets.SelectMultiple(
    options=[],
    description="Parts:",
    disabled=False,
    layout=widgets.Layout(width="95%", height="150px") # Adjusted width and height
)

controls_area = widgets.Output(layout=widgets.Layout(border='1px solid #aaddff', padding='10px', margin='10px 0')) # Added styling
plot_area = widgets.Output()

# Global store
current_segment_widgets = []
plotter = pv.Plotter(notebook=True)


# --- Build widgets for each selected part ---
def make_widgets(segmentation_files):
    widgets_list = []
    initial_colors = ["#FF6347", "#4682B4", "#32CD32", "#FFD700", "#9370DB", "#00CED1", "#FF8C00", "#FF69B4"] # More visually appealing colors

    for i, seg_file in enumerate(segmentation_files):
        color_picker = widgets.ColorPicker(
            concise=False, # Changed to concise=False
            description=f"{seg_file.replace('.nii.gz', '')} Color:", # Shortened description
            value=initial_colors[i % len(initial_colors)],
            layout=widgets.Layout(width="150px") # Fixed width
        )
        opacity_slider = widgets.FloatSlider(
            value=0.6, min=0, max=1, step=0.01,
            description="Opacity:", continuous_update=False,
            layout=widgets.Layout(width="250px") # Increased width
        )
        visibility_checkbox = widgets.Checkbox(value=True, description="Visible")

        widgets_list.append({
            "file": seg_file,
            "color_picker": color_picker,
            "opacity_slider": opacity_slider,
            "visibility_checkbox": visibility_checkbox
        })

    return widgets_list


# --- Refresh PyVista plot based on current widget states ---
def refresh_plot(change=None):
    with plot_area:
        clear_output(wait=True)
        plotter.clear_actors()

        for seg_widget in current_segment_widgets:
            seg_file = seg_widget["file"]
            seg_path = os.path.join(segmentations_dir_total, seg_file)

            if not os.path.exists(seg_path):
                print(f"Missing file: {seg_file}")
                continue

            seg_img = nib.load(seg_path)
            seg_data = seg_img.get_fdata()

            if np.sum(seg_data) > 0:
                seg_grid = pv.wrap(seg_data)
                mesh = seg_grid.contour(isosurfaces=[0.5])

                if mesh.n_points > 0:
                    smoothed_mesh = mesh.smooth(n_iter=50, relaxation_factor=0.1)
                    color_val = seg_widget["color_picker"].value
                    opacity = seg_widget["opacity_slider"].value
                    visible = seg_widget["visibility_checkbox"].value
                    if visible:
                        plotter.add_mesh(smoothed_mesh, color=color_val, opacity=opacity, name=seg_file)

        plotter.camera_position = "iso"
        html_output = plotter.show(jupyter_backend="html")
        display(HTML(html_output))


# --- Update available parts when organ changes ---
def update_parts(change=None):
    selected_organ = organ_dropdown.value
    parts_select.options = ["[All]"] + organ_groups[selected_organ]
    parts_select.value = ("[All]",)


# --- Update when parts selection changes ---
def update_plot(change=None):
    global current_segment_widgets

    selected_organ = organ_dropdown.value
    selected_parts = parts_select.value

    if "[All]" in selected_parts:
        segmentation_files = organ_groups[selected_organ]
    else:
        segmentation_files = list(selected_parts)

    # Filter out missing files before making widgets
    existing_segmentation_files = [f for f in segmentation_files if os.path.exists(os.path.join(segmentations_dir_total, f))]


    # Build widgets only once when selection changes
    current_segment_widgets = make_widgets(existing_segmentation_files)

    with controls_area:
        clear_output(wait=True)
        # Arranged widgets in a more compact way
        widget_boxes = [
            widgets.HBox([seg_widget["color_picker"], seg_widget["opacity_slider"], seg_widget["visibility_checkbox"]])
            for seg_widget in current_segment_widgets
        ]
        display(widgets.VBox([widgets.Label("Adjust Segmentation Appearance:")] + widget_boxes, layout=widgets.Layout(border='1px solid #ccffcc', padding='10px', margin='10px 0'))) # Added styling


        # Hook widget changes to refresh_plot (not rebuild!)
        for seg_widget in current_segment_widgets:
            seg_widget["color_picker"].observe(refresh_plot, names="value")
            seg_widget["opacity_slider"].observe(refresh_plot, names="value")
            seg_widget["visibility_checkbox"].observe(refresh_plot, names="value")

    refresh_plot()


# Hook changes
organ_dropdown.observe(update_parts, names="value")
parts_select.observe(update_plot, names="value")

# Display UI
# Reverted to a more vertical layout with styled containers
main_layout = widgets.VBox([
    widgets.Label("3D Segmentation Visualization", style={'font_weight': 'bold', 'font_size': '16px'}), # Added title
    widgets.HBox([organ_dropdown, parts_select]),
    controls_area,
    plot_area
], layout=widgets.Layout(border='2px solid #cccccc', padding='20px', background='#f0f0f0')) # Added overall container styling
display(main_layout)

# Initial state
update_parts()
update_plot()

# Cell 5: Evaluation and metrics

# ----------------- CONFIG -----------------
raw_file = "/content/s0010/ct.nii.gz"                 # raw CT
gt_dir   = "/content/s0010/segmentations"            # ground-truth masks
pred_dir = "/content/segmentation_output"        # predicted masks

# The organ groups we visualize (display names -> their component filenames prefix)
organs_display = {
    "Ribs": [f"rib_left_{i}" for i in range(1, 13)] + [f"rib_right_{i}" for i in range(1, 13)],
    "Lungs": ["lung_upper_lobe_left", "lung_upper_lobe_right",
              "lung_middle_lobe_right", "lung_lower_lobe_left",
              "lung_lower_lobe_right"],
    "Vertebrae": ["vertebrae_L1", "vertebrae_L2", "vertebrae_L3",
                  "vertebrae_L4", "vertebrae_L5", "vertebrae_S1",
                  "vertebrae_T8", "vertebrae_T9", "vertebrae_T10",
                  "vertebrae_T11", "vertebrae_T12"]
}
# Mapping from display-name -> organ-key used in CSV (adjust if your CSV uses other names)
csv_organ_key = {
    "Ribs": "ribs",
    "Lungs": "lungs",
    "Vertebrae": "vertebrae"
}
# Candidate CSV filenames/paths to try
csv_candidates = [
    "evaluation_results_filtered.csv",
    "evaluation_results.csv",
    "/content/evaluation_results_filtered.csv",
    "/content/evaluation_results.csv",
    "/content/s0015/evaluation_results_filtered.csv",
    "/content/s0015/evaluation_results.csv"
]
# -------------------------------------------

# Load raw image
if not os.path.exists(raw_file):
    raise FileNotFoundError(f"Raw file not found: {raw_file}")
raw_img = nib.load(raw_file)
raw_data = raw_img.get_fdata()
nx, ny, nz = raw_data.shape

# Try to find CSV
csv_path = None
for p in csv_candidates:
    if os.path.exists(p):
        csv_path = p
        break

if csv_path:
    print("Loaded metrics CSV:", csv_path)
    df_csv = pd.read_csv(csv_path)
    # ensure lowercase columns
    df_csv.columns = [c.lower() for c in df_csv.columns]
    if 'organ' not in df_csv.columns:
        print("Warning: CSV does not contain 'organ' column — falling back to compute metrics.")
        df_group = None
    else:
        # group by organ and average
        # keep dice,iou,hd95 columns if present
        metric_cols = [c for c in ['dice','iou','hd95'] if c in df_csv.columns]
        if len(metric_cols) == 0:
            df_group = None
        else:
            df_group = df_csv.groupby('organ')[metric_cols].mean()
            print("Per-organ averages from CSV:")
            display(df_group)
else:
    print("No CSV found in candidates. Will compute metrics from masks if needed.")
    df_group = None

# Utility metrics fallback (if CSV missing metric)
def dice_bin(gt, pred):
    gt_b = (gt > 0)
    pr_b = (pred > 0)
    if gt_b.sum() == 0 and pr_b.sum() == 0:
        return 1.0
    inter = np.logical_and(gt_b, pr_b).sum()
    return 2.0 * inter / (gt_b.sum() + pr_b.sum() + 1e-12)

def iou_bin(gt, pred):
    gt_b = (gt > 0)
    pr_b = (pred > 0)
    if gt_b.sum() == 0 and pr_b.sum() == 0:
        return 1.0
    inter = np.logical_and(gt_b, pr_b).sum()
    union = np.logical_or(gt_b, pr_b).sum()
    return inter / (union + 1e-12)

def hd95_bin(gt, pred):
    try:
        from medpy.metric.binary import hd95 as medpy_hd95
        MEDPY_AVAILABLE = True
    except Exception:
        MEDPY_AVAILABLE = False

    if not MEDPY_AVAILABLE:
        return np.nan
    gt_b = (gt > 0).astype(np.uint8)
    pr_b = (pred > 0).astype(np.uint8)
    try:
        return float(medpy_hd95(pr_b, gt_b)) # Ensure float return
    except Exception:
        return np.nan

# Precompute labeled volumes per organ and prepare colormaps + metrics (use CSV averages if available)
base_cmap = plt.colormaps.get_cmap("tab20")

organ_data = {}
for display_name, parts in organs_display.items():
    n_parts = len(parts)
    gt_lab = np.zeros((nx, ny, nz), dtype=np.int16)
    pr_lab = np.zeros((nx, ny, nz), dtype=np.int16)

    # load parts into labeled volumes (label 1..n_parts)
    for idx, part_prefix in enumerate(parts, start=1):
        fname = part_prefix + ".nii.gz"
        gt_path = os.path.join(gt_dir, fname)
        pr_path = os.path.join(pred_dir, fname)
        if os.path.exists(gt_path):
            arr = nib.load(gt_path).get_fdata() > 0
            gt_lab[arr & (gt_lab == 0)] = idx
        if os.path.exists(pr_path):
            arrp = nib.load(pr_path).get_fdata() > 0
            pr_lab[arrp & (pr_lab == 0)] = idx

    # prepare ListedColormap: background transparent + per-part rgba
    rgba_colors = [base_cmap(i % base_cmap.N) for i in range(n_parts)]
    gt_colors = [(0,0,0,0.0)] + [(r,g,b,0.75) for (r,g,b,_) in rgba_colors]
    pr_colors = [(0,0,0,0.0)] + [(r,g,b,0.40) for (r,g,b,_) in rgba_colors]
    gt_cmap = ListedColormap(gt_colors)
    pr_cmap = ListedColormap(pr_colors)

    # metrics: prefer CSV averages if available
    csv_key = csv_organ_key.get(display_name, display_name.lower())
    metrics = {"dice": np.nan, "iou": np.nan, "hd95": np.nan}
    if df_group is not None and csv_key in df_group.index:
        row = df_group.loc[csv_key]
        for col in ['dice','iou','hd95']:
            if col in row.index:
                metrics[col] = float(row[col])
    else:
        # fallback: compute from combined binary masks
        gt_combined = (gt_lab > 0).astype(np.uint8)
        pr_combined = (pr_lab > 0).astype(np.uint8)
        metrics['dice'] = dice_bin(gt_combined, pr_combined)
        metrics['iou'] = iou_bin(gt_combined, pr_combined)
        metrics['hd95'] = hd95_bin(gt_combined, pr_combined)


    organ_data[display_name] = {
        "parts": parts,
        "n_parts": n_parts,
        "gt_lab": gt_lab,
        "pr_lab": pr_lab,
        "gt_cmap": gt_cmap,
        "pr_cmap": pr_cmap,
        "metrics": metrics
    }

# Build interactive UI: one slider + output per organ (images draw inside the output)
ui_widgets = []
for organ, info in organ_data.items():
    max_slice = nz - 1
    slider = widgets.IntSlider(min=0, max=max_slice, step=1, value=max_slice//2,
                               description=f"{organ} slice", layout=widgets.Layout(width="80%", margin="0 0 10px 0"))
    out = widgets.Output(layout=widgets.Layout(border="1px solid #ddd", margin="0 0 20px 0"))

    def make_handler(organ, slider, out):
        info = organ_data[organ]
        def handler(change):
            slice_idx = change['new'] if isinstance(change, dict) else slider.value
            with out:
                clear_output(wait=True)
                raw_slice = raw_data[:, :, slice_idx]
                gt_slice = info["gt_lab"][:, :, slice_idx]
                pr_slice = info["pr_lab"][:, :, slice_idx]

                fig, axes = plt.subplots(1, 3, figsize=(15, 5))
                axes[0].imshow(raw_slice.T, cmap="gray", origin="lower")
                axes[0].set_title(f"{organ} — Raw")
                axes[0].axis("off")

                axes[1].imshow(raw_slice.T, cmap="gray", origin="lower")
                axes[1].imshow(gt_slice.T, cmap=info["gt_cmap"], origin="lower", vmin=0, vmax=info["n_parts"])
                axes[1].set_title("Ground Truth (parts)")
                axes[1].axis("off")

                axes[2].imshow(raw_slice.T, cmap="gray", origin="lower")
                axes[2].imshow(pr_slice.T, cmap=info["pr_cmap"], origin="lower", vmin=0, vmax=info["n_parts"])
                axes[2].set_title("Prediction (parts)")
                axes[2].axis("off")

                # metrics text under figure (from CSV averages if available)
                m = info["metrics"]
                met_text = f"Dice: {m['dice']:.4f}    IoU: {m['iou']:.4f}    HD95: {m['hd95'] if (not np.isnan(m['hd95'])) else 'nan'}"
                fig.text(0.5, -0.05, met_text, ha='center', fontsize=11) # Adjusted text position

                display(fig)
                plt.close(fig)
        return handler

    handler = make_handler(organ, slider, out)
    slider.observe(handler, names='value')
    # initial render
    handler({'new': slider.value})
    ui_widgets.append(widgets.VBox([widgets.Label(f"Organ: {organ}"), slider, out])) # Added organ label

# Show them stacked
display(widgets.VBox(ui_widgets, layout=widgets.Layout(border="1px solid #ccc", padding="20px"))) # Added border and padding