# -*- coding: utf-8 -*-
"""Copy of Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3HNNQdm6nhZeHt9zjaZz3Bz_8MXMvhA
"""

!pip install gdown

!gdown --id 1l6ViBkrONX5KAdziNfeB7G3AS98pb5WV

!unzip CT_subset_big.zip

# Cell 1 - install dependencies (run once)
!pip install --quiet gdown nibabel numpy scipy scikit-image matplotlib ipywidgets pyvista[all] totalsegmentator

# Enable widgets extension (harmless if already enabled)
!jupyter nbextension enable --py widgetsnbextension || true

print("✅ Installed libraries (may have re-used cached packages).")

import nibabel as nib
import matplotlib.pyplot as plt
from ipywidgets import interactive, IntSlider
from IPython.display import display

def show_nii_slice(nii_path, slice_idx):
    img = nib.load(nii_path)
    data = img.get_fdata()
    plt.imshow(data[:, :, slice_idx], cmap='gray')
    plt.title(f'Slice {slice_idx}')
    plt.axis('off')
    plt.show()

nii_file_path = '/content/s0010/ct.nii.gz'
img = nib.load(nii_file_path)
data = img.get_fdata()
max_slices = data.shape[2] - 1

interactive_plot = interactive(
    show_nii_slice,
    nii_path=nii_file_path,
    slice_idx=IntSlider(min=0, max=max_slices, step=1, description='Slice:')
)
display(interactive_plot)

# --- Step 1: Install dependencies ---
!pip install TotalSegmentator itk

# Install MedIM and required dependencies
!pip install medim
!pip install nibabel numpy torch torchvision
!pip install monai  # For medical image preprocessing utilities

# TotalSegmentator organ class mapping (104 classes + background)
# Based on TotalSegmentator v1 (104 anatomical structures)
TOTALSEGMENTATOR_CLASS_MAPPING = {
    0: "background",
    1: "adrenal_gland_left",
    2: "adrenal_gland_right",
    3: "aorta",
    4: "autochthon_left",
    5: "autochthon_right",
    6: "brain",
    7: "clavicula_left",
    8: "clavicula_right",
    9: "colon",
    10: "duodenum",
    11: "esophagus",
    12: "face",
    13: "femur_left",
    14: "femur_right",
    15: "gallbladder",
    16: "gluteus_maximus_left",
    17: "gluteus_maximus_right",
    18: "gluteus_medius_left",
    19: "gluteus_medius_right",
    20: "gluteus_minimus_left",
    21: "gluteus_minimus_right",
    22: "heart_atrium_left",
    23: "heart_atrium_right",
    24: "heart_myocardium",
    25: "heart_ventricle_left",
    26: "heart_ventricle_right",
    27: "hip_left",
    28: "hip_right",
    29: "humerus_left",
    30: "humerus_right",
    31: "iliac_artery_left",
    32: "iliac_artery_right",
    33: "iliac_vena_left",
    34: "iliac_vena_right",
    35: "iliopsoas_left",
    36: "iliopsoas_right",
    37: "inferior_vena_cava",
    38: "kidney_left",
    39: "kidney_right",
    40: "liver",
    41: "lung_lower_lobe_left",
    42: "lung_lower_lobe_right",
    43: "lung_middle_lobe_right",
    44: "lung_upper_lobe_left",
    45: "lung_upper_lobe_right",
    46: "pancreas",
    47: "portal_vein_and_splenic_vein",
    48: "pulmonary_artery",
    49: "rib_left_1",
    50: "rib_left_10",
    51: "rib_left_11",
    52: "rib_left_12",
    53: "rib_left_2",
    54: "rib_left_3",
    55: "rib_left_4",
    56: "rib_left_5",
    57: "rib_left_6",
    58: "rib_left_7",
    59: "rib_left_8",
    60: "rib_left_9",
    61: "rib_right_1",
    62: "rib_right_10",
    63: "rib_right_11",
    64: "rib_right_12",
    65: "rib_right_2",
    66: "rib_right_3",
    67: "rib_right_4",
    68: "rib_right_5",
    69: "rib_right_6",
    70: "rib_right_7",
    71: "rib_right_8",
    72: "rib_right_9",
    73: "sacrum",
    74: "scapula_left",
    75: "scapula_right",
    76: "small_bowel",
    77: "spleen",
    78: "stomach",
    79: "trachea",
    80: "urinary_bladder",
    81: "vertebrae_C1",
    82: "vertebrae_C2",
    83: "vertebrae_C3",
    84: "vertebrae_C4",
    85: "vertebrae_C5",
    86: "vertebrae_C6",
    87: "vertebrae_C7",
    88: "vertebrae_L1",
    89: "vertebrae_L2",
    90: "vertebrae_L3",
    91: "vertebrae_L4",
    92: "vertebrae_L5",
    93: "vertebrae_T1",
    94: "vertebrae_T10",
    95: "vertebrae_T11",
    96: "vertebrae_T12",
    97: "vertebrae_T2",
    98: "vertebrae_T3",
    99: "vertebrae_T4",
    100: "vertebrae_T5",
    101: "vertebrae_T6",
    102: "vertebrae_T7",
    103: "vertebrae_T8",
    104: "vertebrae_T9"
}

import os
import shutil
import torch
import numpy as np
import nibabel as nib
from scipy import ndimage
import medim

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Input CT scan
input_file = '/content/s0016/ct.nii.gz'

# Define output directory
output_dir_medim = "segmentations_medim_out"

# Remove existing output directory if it exists
if os.path.exists(output_dir_medim):
    shutil.rmtree(output_dir_medim)
    print(f"Removed directory: {output_dir_medim}")

# Create output directory
os.makedirs(output_dir_medim, exist_ok=True)

def preprocess_ct_scan(input_file, target_spacing=(1.5, 1.5, 1.5), target_size=(128, 128, 128)):
    """
    Preprocess CT scan for MedIM STU-Net model
    """
    print("Loading and preprocessing CT scan...")

    # Load NIfTI file
    img = nib.load(input_file)
    data = img.get_fdata().astype(np.float32)

    # Get original spacing and affine
    original_spacing = img.header.get_zooms()[:3]
    affine = img.affine

    print(f"Original shape: {data.shape}")
    print(f"Original spacing: {original_spacing}")

    # Clip HU values (typical CT range)
    data = np.clip(data, -1024, 1024)

    # Normalize to [0, 1] range
    data = (data + 1024) / 2048.0

    # Resample to target spacing if needed
    if original_spacing != target_spacing:
        zoom_factors = [orig/target for orig, target in zip(original_spacing, target_spacing)]
        data = ndimage.zoom(data, zoom_factors, order=1, mode='nearest')
        print(f"Resampled shape: {data.shape}")

    # Resize to target size for model input
    current_shape = data.shape
    resize_factors = [target/current for target, current in zip(target_size, current_shape)]
    data_resized = ndimage.zoom(data, resize_factors, order=1, mode='nearest')

    print(f"Final preprocessed shape: {data_resized.shape}")

    # Convert to tensor and add batch and channel dimensions
    data_tensor = torch.from_numpy(data_resized).float()
    data_tensor = data_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, H, W, D)

    return data_tensor, data, current_shape, affine, img.header

def postprocess_segmentation(pred_tensor, original_shape, original_affine, original_header, output_dir):
    """
    Postprocess segmentation results and save individual organ masks with proper names
    """
    print("Postprocessing segmentation results...")

    # Remove batch dimension and convert to numpy
    pred_np = pred_tensor.squeeze(0).cpu().numpy()  # (num_classes, H, W, D)

    # Get number of classes
    num_classes = pred_np.shape[0]
    print(f"Number of segmented classes: {num_classes}")

    # Resize back to original CT scan dimensions
    resize_factors = [orig/current for orig, current in zip(original_shape, pred_np.shape[1:])]

    # Create a multi-label segmentation volume
    multi_label_seg = np.zeros(original_shape, dtype=np.uint16)

    # Keep track of saved organs
    saved_organs = []

    # Process each class
    for class_idx in range(num_classes):
        if class_idx == 0:  # Skip background class
            continue

        # Get class probability map
        class_prob = pred_np[class_idx]

        # Resize to original dimensions
        class_resized = ndimage.zoom(class_prob, resize_factors, order=1, mode='nearest')

        # Threshold to get binary mask (adjust threshold as needed)
        class_mask = (class_resized > 0.5).astype(np.uint16)

        # Add to multi-label volume
        multi_label_seg[class_mask > 0] = class_idx

        # Save individual organ mask with proper name
        if np.sum(class_mask) > 0:  # Only save non-empty masks
            # Get organ name from mapping
            organ_name = TOTALSEGMENTATOR_CLASS_MAPPING.get(class_idx, f"unknown_class_{class_idx}")

            organ_img = nib.Nifti1Image(class_mask, original_affine, original_header)
            organ_filename = os.path.join(output_dir, f"{organ_name}.nii.gz")
            nib.save(organ_img, organ_filename)

            voxel_count = np.sum(class_mask)
            saved_organs.append((organ_name, voxel_count))
            print(f"Saved {organ_name}: {voxel_count} voxels")

    # Save multi-label segmentation
    multi_label_img = nib.Nifti1Image(multi_label_seg, original_affine, original_header)
    multi_label_filename = os.path.join(output_dir, "segmentations.nii.gz")
    nib.save(multi_label_img, multi_label_filename)
    print(f"Saved multi-label segmentation: {multi_label_filename}")

    # Print summary of saved organs
    print(f"\nSegmentation Summary:")
    print(f"Total organs segmented: {len(saved_organs)}")
    print("Organs found:")
    for organ_name, voxel_count in sorted(saved_organs, key=lambda x: x[1], reverse=True):
        print(f"  - {organ_name}: {voxel_count:,} voxels")

    return multi_label_seg

def run_medim_segmentation(input_file, output_dir):
    """
    Main function to run MedIM segmentation
    """
    print("Creating MedIM model...")

    # Create STU-Net model pre-trained on TotalSegmentator dataset
    # This should give similar results to TotalSegmentator
    # In run_medim_segmentation function:
    model = medim.create_model("STU-Net-L", dataset="TotalSegmentator")
    model = model.to(device)
    model.eval()

    print("Model loaded successfully!")

    # Preprocess input
    input_tensor, original_data, original_shape, affine, header = preprocess_ct_scan(input_file)
    input_tensor = input_tensor.to(device)

    print("Running inference...")
    with torch.no_grad():
        # Run inference
        output = model(input_tensor)

        # Apply softmax to get probabilities
        if len(output.shape) == 5:  # (batch, classes, H, W, D)
            output = torch.softmax(output, dim=1)

    print("Inference completed!")

    # Postprocess and save results
    segmentation_result = postprocess_segmentation(
        output, original_shape, affine, header, output_dir
    )

    return segmentation_result

# Run the segmentation
print(f"Running MedIM segmentation on: {input_file}")
try:
    segmentation_result = run_medim_segmentation(input_file, output_dir_medim)
    print(f"Segmentation completed! Results saved in: {output_dir_medim}")

    # List generated files with proper names
    print("\nGenerated organ files:")
    organ_files = []
    for file in os.listdir(output_dir_medim):
        if file.endswith('.nii.gz') and file != 'segmentations.nii.gz':
            file_path = os.path.join(output_dir_medim, file)
            img = nib.load(file_path)
            data = img.get_fdata()
            non_zero_voxels = np.count_nonzero(data)
            organ_files.append((file.replace('.nii.gz', ''), non_zero_voxels))

    # Sort by voxel count (largest organs first)
    organ_files.sort(key=lambda x: x[1], reverse=True)
    for organ_name, voxel_count in organ_files:
        print(f"  {organ_name}: {voxel_count:,} voxels")

    print(f"\nMain segmentation file: segmentations.nii.gz")
    print(f"Total files created: {len(organ_files) + 1}")

except Exception as e:
    print(f"Error during segmentation: {e}")
    print("This might be due to:")
    print("1. Model not available for the specified dataset")
    print("2. Input image format issues")
    print("3. Memory constraints")

    # Fallback: try with a different model configuration
    print("\nTrying with basic STU-Net model...")
    try:
        model = medim.create_model("STU-Net-S")
        model = model.to(device)
        model.eval()
        print("Basic model loaded - you may need to adapt the preprocessing/postprocessing")
    except Exception as e2:
        print(f"Fallback also failed: {e2}")

# Optional: Clean up empty files (similar to your original code)
def filter_empty_files(output_dir):
    for root, dirs, files in os.walk(output_dir):
        for file in files:
            if file.endswith('.nii.gz'):
                file_path = os.path.join(root, file)
                try:
                    img = nib.load(file_path)
                    data = img.get_fdata()
                    if np.sum(data) == 0:
                        print(f"Removing empty file: {file_path}")
                        os.remove(file_path)
                except Exception as e:
                    print(f"Error processing file {file_path}: {e}")

print("\nFiltering empty files...")
filter_empty_files(output_dir_medim)
print("Processing complete!")

# Cell 1 - install dependencies (run once)
!pip install --quiet gdown nibabel numpy scipy scikit-image matplotlib ipywidgets pyvista[all] totalsegmentator

# Enable widgets extension (harmless if already enabled)
!jupyter nbextension enable --py widgetsnbextension || true

print("✅ Installed libraries (may have re-used cached packages).")

import os
import nibabel as nib
import numpy as np
import pyvista as pv
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML

# Path to segmentations
segmentations_dir_total = "/content/segmentations_medim_out"

# --- Organ group definitions ---
organ_groups = {
    "Lungs": [
        "lung_upper_lobe_left.nii.gz",
        "lung_lower_lobe_left.nii.gz",
        "lung_middle_lobe_right.nii.gz",
        "lung_upper_lobe_right.nii.gz",
        "lung_lower_lobe_right.nii.gz",
    ],
    "Vertebrae": [
        "vertebrae_L1.nii.gz", "vertebrae_L2.nii.gz", "vertebrae_L3.nii.gz",
        "vertebrae_L4.nii.gz", "vertebrae_L5.nii.gz", "vertebrae_S1.nii.gz",
        "vertebrae_T11.nii.gz", "vertebrae_T12.nii.gz","vertebrae_T6.nii.gz",
        "vertebrae_C2.nii.gz","vertebrae_C1.nii.gz"
    ],
    "Gluteal Muscles": [
        "gluteus_maximus_left.nii.gz", "gluteus_maximus_right.nii.gz",
        "gluteus_medius_left.nii.gz", "gluteus_medius_right.nii.gz",
        "gluteus_minimus_left.nii.gz", "gluteus_minimus_right.nii.gz"
    ]
}

# --- UI widgets ---
organ_dropdown = widgets.Dropdown(
    options=list(organ_groups.keys()),
    description="Organ:",
    value="Lungs",
)

parts_select = widgets.SelectMultiple(
    options=[],
    description="Parts:",
    disabled=False,
    layout=widgets.Layout(width="50%", height="200px")
)

controls_area = widgets.Output()
plot_area = widgets.Output()

# Global store
current_segment_widgets = []
plotter = pv.Plotter(notebook=True)


# --- Build widgets for each selected part ---
def make_widgets(segmentation_files):
    widgets_list = []
    initial_colors = ["red", "green", "blue", "yellow", "purple", "cyan", "orange", "pink"]

    for i, seg_file in enumerate(segmentation_files):
        color_picker = widgets.ColorPicker(
            concise=True,
            description=f"{seg_file} Color:",
            value=initial_colors[i % len(initial_colors)],
        )
        opacity_slider = widgets.FloatSlider(
            value=0.6, min=0, max=1, step=0.01,
            description="Opacity:", continuous_update=False
        )
        visibility_checkbox = widgets.Checkbox(value=True, description="Visible")

        widgets_list.append({
            "file": seg_file,
            "color_picker": color_picker,
            "opacity_slider": opacity_slider,
            "visibility_checkbox": visibility_checkbox
        })

    return widgets_list


# --- Refresh PyVista plot based on current widget states ---
def refresh_plot(change=None):
    with plot_area:
        clear_output(wait=True)
        plotter.clear_actors()

        for seg_widget in current_segment_widgets:
            seg_file = seg_widget["file"]
            seg_path = os.path.join(segmentations_dir_total, seg_file)

            if not os.path.exists(seg_path):
                print(f"Missing file: {seg_file}")
                continue

            seg_img = nib.load(seg_path)
            seg_data = seg_img.get_fdata()

            if np.sum(seg_data) > 0:
                seg_grid = pv.wrap(seg_data)
                mesh = seg_grid.contour(isosurfaces=[0.5])

                if mesh.n_points > 0:
                    smoothed_mesh = mesh.smooth(n_iter=50, relaxation_factor=0.1)
                    color_val = seg_widget["color_picker"].value
                    opacity = seg_widget["opacity_slider"].value
                    visible = seg_widget["visibility_checkbox"].value
                    if visible:
                        plotter.add_mesh(smoothed_mesh, color=color_val, opacity=opacity, name=seg_file)

        plotter.camera_position = "iso"
        html_output = plotter.show(jupyter_backend="html")
        display(HTML(html_output))


# --- Update available parts when organ changes ---
def update_parts(change=None):
    selected_organ = organ_dropdown.value
    parts_select.options = ["[All]"] + organ_groups[selected_organ]
    parts_select.value = ("[All]",)


# --- Update when parts selection changes ---
def update_plot(change=None):
    global current_segment_widgets

    selected_organ = organ_dropdown.value
    selected_parts = parts_select.value

    if "[All]" in selected_parts:
        segmentation_files = organ_groups[selected_organ]
    else:
        segmentation_files = list(selected_parts)

    # Build widgets only once when selection changes
    current_segment_widgets = make_widgets(segmentation_files)

    with controls_area:
        clear_output(wait=True)
        widget_boxes = [
            widgets.HBox([seg_widget["color_picker"],
                          seg_widget["opacity_slider"],
                          seg_widget["visibility_checkbox"]])
            for seg_widget in current_segment_widgets
        ]
        display(widgets.VBox(widget_boxes))

        # Hook widget changes to refresh_plot (not rebuild!)
        for seg_widget in current_segment_widgets:
            seg_widget["color_picker"].observe(refresh_plot, names="value")
            seg_widget["opacity_slider"].observe(refresh_plot, names="value")
            seg_widget["visibility_checkbox"].observe(refresh_plot, names="value")

    refresh_plot()


# Hook changes
organ_dropdown.observe(update_parts, names="value")
parts_select.observe(update_plot, names="value")

# Display UI
display(organ_dropdown, parts_select, controls_area, plot_area)

# Initial state
update_parts()
update_plot()

!pip install medpy

import os
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
import ipywidgets as widgets
from IPython.display import display
from tqdm import tqdm
import pandas as pd
from medpy.metric.binary import hd95

# Paths
pred_dir = "/content/segmentations_medim_out"
gt_dir = "/content/s0016/segmentations"

# Organs of interest (keywords to match in filenames)
organs_of_interest = {
    "lungs": ["lung_upper_lobe_left", "lung_upper_lobe_right",
              "lung_middle_lobe_right", "lung_lower_lobe_left",
              "lung_lower_lobe_right"],
    "gluteal_muscles": ["gluteus_maximus_left", "gluteus_maximus_right",
                        "gluteus_medius_left", "gluteus_medius_right",
                        "gluteus_minimus_left", "gluteus_minimus_right"],
    "vertebrae": ["vertebrae_L1", "vertebrae_L2", "vertebrae_L3",
                  "vertebrae_L4", "vertebrae_L5", "vertebrae_S1",
                  "vertebrae_T8", "vertebrae_T9", "vertebrae_T10",
                  "vertebrae_T11", "vertebrae_T12"]
}

# Collect only files that match our organs
pred_files = set(os.listdir(pred_dir))
gt_files = set(os.listdir(gt_dir))
common_files = sorted(list(pred_files & gt_files))

filtered_files = []
for fname in common_files:
    for organ, keywords in organs_of_interest.items():
        if any(fname.startswith(k) for k in keywords):
            filtered_files.append((fname, organ))
            break

print(f"✅ Found {len(filtered_files)} matching files for organs of interest")

# --- Metrics ---
def dice_coef(pred, gt):
    inter = np.sum(pred * gt)
    return (2. * inter) / (np.sum(pred) + np.sum(gt) + 1e-8)

def iou_coef(pred, gt):
    inter = np.sum(pred * gt)
    union = np.sum(pred) + np.sum(gt) - inter
    return inter / (union + 1e-8)

# --- Evaluation ---
results = []
for fname, organ in tqdm(filtered_files, desc="Evaluating"):
    pred_img = nib.load(os.path.join(pred_dir, fname)).get_fdata()
    gt_img = nib.load(os.path.join(gt_dir, fname)).get_fdata()

    pred_bin = (pred_img > 0).astype(np.uint8)
    gt_bin = (gt_img > 0).astype(np.uint8)

    dice = dice_coef(pred_bin, gt_bin)
    iou = iou_coef(pred_bin, gt_bin)
    try:
        hd95_val = hd95(pred_bin, gt_bin)
    except Exception:
        hd95_val = np.nan

    results.append({
        "file": fname,
        "organ": organ,
        "dice": dice,
        "iou": iou,
        "hd95": hd95_val
    })

# Save results
df = pd.DataFrame(results)
df.to_csv("evaluation_results_filtered.csv", index=False)

print("\nSummary per organ:")
print(df.groupby("organ")[["dice", "iou", "hd95"]].mean())

print("\nSaved per-file metrics to: evaluation_results_filtered.csv")

# Paths
raw_file = "/content/s0016/ct.nii.gz"
pred_dir = "/content/segmentations_medim_out"
gt_dir = "/content/s0016/segmentations"

# Organs of interest with sub-parts
organs_of_interest = {
    "Gluteus": ["gluteus_maximus_left", "gluteus_maximus_right",
                "gluteus_medius_left", "gluteus_medius_right",
                "gluteus_minimus_left", "gluteus_minimus_right"],
    "Lungs": ["lung_upper_lobe_left", "lung_upper_lobe_right",
              "lung_middle_lobe_right", "lung_lower_lobe_left",
              "lung_lower_lobe_right"],
    "Vertebrae": ["vertebrae_L1", "vertebrae_L2", "vertebrae_L3",
                  "vertebrae_L4", "vertebrae_L5", "vertebrae_S1",
                  "vertebrae_T8", "vertebrae_T9", "vertebrae_T10",
                  "vertebrae_T11", "vertebrae_T12"]
}

# Load raw scan
raw_img = nib.load(raw_file)
raw_data = raw_img.get_fdata()

# Precompute labeled masks (GT and Pred)
combined_gt = {}
combined_pred = {}
for organ_name, keywords in organs_of_interest.items():
    gt_mask = np.zeros_like(raw_data, dtype=np.int16)
    pred_mask = np.zeros_like(raw_data, dtype=np.int16)

    for idx, k in enumerate(keywords, start=1):
        fname = k + ".nii.gz"
        gt_path = os.path.join(gt_dir, fname)
        pred_path = os.path.join(pred_dir, fname)

        if os.path.exists(gt_path):
            gt_img = nib.load(gt_path).get_fdata()
            gt_mask[gt_img > 0] = idx
        if os.path.exists(pred_path):
            pred_img = nib.load(pred_path).get_fdata()
            pred_mask[pred_img > 0] = idx

    combined_gt[organ_name] = gt_mask
    combined_pred[organ_name] = pred_mask

# Function to display one organ with slider
def display_organ_with_slider(organ_name):
    gt_mask = combined_gt[organ_name]
    pred_mask = combined_pred[organ_name]
    cmap = plt.colormaps.get_cmap("tab20")  # 20 unique colors

    max_slice = raw_data.shape[2] - 1

    def update(slice_idx):
        raw_slice = raw_data[:, :, slice_idx]
        gt_slice = gt_mask[:, :, slice_idx]
        pred_slice = pred_mask[:, :, slice_idx]

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # Raw
        axes[0].imshow(raw_slice.T, cmap="gray", origin="lower")
        axes[0].set_title(f"{organ_name} - Raw")
        axes[0].axis("off")

        # GT with distinct colors
        axes[1].imshow(raw_slice.T, cmap="gray", origin="lower")
        axes[1].imshow(gt_slice.T, cmap=cmap, alpha=0.5, origin="lower", vmin=0, vmax=20)
        axes[1].set_title("GT Masks (colored)")
        axes[1].axis("off")

        # Pred with same color mapping
        axes[2].imshow(raw_slice.T, cmap="gray", origin="lower")
        axes[2].imshow(pred_slice.T, cmap=cmap, alpha=0.5, origin="lower", vmin=0, vmax=20)
        axes[2].set_title("Pred Masks (colored)")
        axes[2].axis("off")

        plt.show()

    slider = widgets.IntSlider(min=0, max=max_slice, step=1, value=max_slice // 2,
                               description=f"{organ_name} Slice")
    widgets.interact(update, slice_idx=slider)

# Display all organs
for organ in organs_of_interest.keys():
    display_organ_with_slider(organ)

# # Load CSV averages and show them under each organ row (interactive viewer)
# import os
# import nibabel as nib
# import numpy as np
# import matplotlib.pyplot as plt
# import ipywidgets as widgets
# from IPython.display import display, clear_output
# import pandas as pd
# from matplotlib.colors import ListedColormap

# # Try to import medpy hd95 (optional)
# try:
#     from medpy.metric.binary import hd95 as medpy_hd95
#     MEDPY_AVAILABLE = True
# except Exception:
#     MEDPY_AVAILABLE = False

# # ----------------- CONFIG -----------------
# raw_file = "/content/s0016/ct.nii.gz"                 # raw CT
# gt_dir   = "/content/s0016/segmentations"            # ground-truth masks
# pred_dir = "/content/segmentations_total_out"        # predicted masks

# # The organ groups we visualize (display names -> their component filenames prefix)
# organs_display = {
#     "Gluteus": ["gluteus_maximus_left", "gluteus_maximus_right",
#                 "gluteus_medius_left", "gluteus_medius_right",
#                 "gluteus_minimus_left", "gluteus_minimus_right"],
#     "Lungs": ["lung_upper_lobe_left", "lung_upper_lobe_right",
#               "lung_middle_lobe_right", "lung_lower_lobe_left",
#               "lung_lower_lobe_right"],
#     "Vertebrae": ["vertebrae_L1", "vertebrae_L2", "vertebrae_L3",
#                   "vertebrae_L4", "vertebrae_L5", "vertebrae_S1",
#                   "vertebrae_T8", "vertebrae_T9", "vertebrae_T10",
#                   "vertebrae_T11", "vertebrae_T12"]
# }
# # Mapping from display-name -> organ-key used in CSV (adjust if your CSV uses other names)
# csv_organ_key = {
#     "Gluteus": "gluteal_muscles",
#     "Lungs": "lungs",
#     "Vertebrae": "vertebrae"
# }
# # Candidate CSV filenames/paths to try
# csv_candidates = [
#     "evaluation_results_filtered.csv",
#     "evaluation_results.csv",
#     "/content/evaluation_results_filtered.csv",
#     "/content/evaluation_results.csv",
#     "/content/s0010/evaluation_results_filtered.csv",
#     "/content/s0010/evaluation_results.csv"
# ]
# # -------------------------------------------

# # Load raw image
# if not os.path.exists(raw_file):
#     raise FileNotFoundError(f"Raw file not found: {raw_file}")
# raw_img = nib.load(raw_file)
# raw_data = raw_img.get_fdata()
# nx, ny, nz = raw_data.shape

# # Try to find CSV
# csv_path = None
# for p in csv_candidates:
#     if os.path.exists(p):
#         csv_path = p
#         break

# if csv_path:
#     print("Loaded metrics CSV:", csv_path)
#     df_csv = pd.read_csv(csv_path)
#     # ensure lowercase columns
#     df_csv.columns = [c.lower() for c in df_csv.columns]
#     if 'organ' not in df_csv.columns:
#         print("Warning: CSV does not contain 'organ' column — falling back to compute metrics.")
#         df_group = None
#     else:
#         # group by organ and average
#         # keep dice,iou,hd95 columns if present
#         metric_cols = [c for c in ['dice','iou','hd95'] if c in df_csv.columns]
#         if len(metric_cols) == 0:
#             df_group = None
#         else:
#             df_group = df_csv.groupby('organ')[metric_cols].mean()
#             print("Per-organ averages from CSV:")
#             display(df_group)
# else:
#     print("No CSV found in candidates. Will compute metrics from masks if needed.")
#     df_group = None

# # Utility metrics fallback (if CSV missing metric)
# def dice_bin(gt, pred):
#     gt_b = (gt > 0)
#     pr_b = (pred > 0)
#     if gt_b.sum() == 0 and pr_b.sum() == 0:
#         return 1.0
#     inter = np.logical_and(gt_b, pr_b).sum()
#     return 2.0 * inter / (gt_b.sum() + pr_b.sum() + 1e-12)

# def iou_bin(gt, pred):
#     gt_b = (gt > 0)
#     pr_b = (pred > 0)
#     if gt_b.sum() == 0 and pr_b.sum() == 0:
#         return 1.0
#     inter = np.logical_and(gt_b, pr_b).sum()
#     union = np.logical_or(gt_b, pr_b).sum()
#     return inter / (union + 1e-12)

# def hd95_bin(gt, pred):
#     if not MEDPY_AVAILABLE:
#         return np.nan
#     gt_b = (gt > 0).astype(np.uint8)
#     pr_b = (pred > 0).astype(np.uint8)
#     try:
#         return float(medpy_hd95(pr_b, gt_b))
#     except Exception:
#         return np.nan

# # Precompute labeled volumes per organ and prepare colormaps + metrics (use CSV averages if available)
# from matplotlib import cm
# base_cmap = plt.colormaps.get_cmap("tab20")

# organ_data = {}
# for display_name, parts in organs_display.items():
#     n_parts = len(parts)
#     gt_lab = np.zeros((nx, ny, nz), dtype=np.int16)
#     pr_lab = np.zeros((nx, ny, nz), dtype=np.int16)

#     # load parts into labeled volumes (label 1..n_parts)
#     for idx, part_prefix in enumerate(parts, start=1):
#         fname = part_prefix + ".nii.gz"
#         gt_path = os.path.join(gt_dir, fname)
#         pr_path = os.path.join(pred_dir, fname)
#         if os.path.exists(gt_path):
#             arr = nib.load(gt_path).get_fdata() > 0
#             gt_lab[arr & (gt_lab == 0)] = idx
#         if os.path.exists(pr_path):
#             arrp = nib.load(pr_path).get_fdata() > 0
#             pr_lab[arrp & (pr_lab == 0)] = idx

#     # prepare ListedColormap: background transparent + per-part rgba
#     rgba_colors = [base_cmap(i % base_cmap.N) for i in range(n_parts)]
#     gt_colors = [(0,0,0,0.0)] + [(r,g,b,0.75) for (r,g,b,_) in rgba_colors]
#     pr_colors = [(0,0,0,0.0)] + [(r,g,b,0.40) for (r,g,b,_) in rgba_colors]
#     gt_cmap = ListedColormap(gt_colors)
#     pr_cmap = ListedColormap(pr_colors)

#     # metrics: prefer CSV averages if available
#     csv_key = csv_organ_key.get(display_name, display_name.lower())
#     metrics = {"dice": np.nan, "iou": np.nan, "hd95": np.nan}
#     if df_group is not None and csv_key in df_group.index:
#         row = df_group.loc[csv_key]
#         for col in ['dice','iou','hd95']:
#             if col in row.index:
#                 metrics[col] = float(row[col])
#     else:
#         # fallback: compute from combined binary masks
#         gt_combined = (gt_lab > 0).astype(np.uint8)
#         pr_combined = (pr_lab > 0).astype(np.uint8)
#         metrics['dice'] = dice_bin(gt_combined, pr_combined)
#         metrics['iou'] = iou_bin(gt_combined, pr_combined)
#         metrics['hd95'] = hd95_bin(gt_combined, pr_combined)

#     organ_data[display_name] = {
#         "parts": parts,
#         "n_parts": n_parts,
#         "gt_lab": gt_lab,
#         "pr_lab": pr_lab,
#         "gt_cmap": gt_cmap,
#         "pr_cmap": pr_cmap,
#         "metrics": metrics
#     }

# # Build interactive UI: one slider + output per organ (images draw inside the output)
# ui_widgets = []
# for organ, info in organ_data.items():
#     max_slice = nz - 1
#     slider = widgets.IntSlider(min=0, max=max_slice, step=1, value=max_slice//2,
#                                description=f"{organ} slice", layout=widgets.Layout(width="80%"))
#     out = widgets.Output(layout=widgets.Layout(border="1px solid #ddd"))

#     def make_handler(organ, slider, out):
#         info = organ_data[organ]
#         def handler(change):
#             slice_idx = change['new'] if isinstance(change, dict) else slider.value
#             with out:
#                 clear_output(wait=True)
#                 raw_slice = raw_data[:, :, slice_idx]
#                 gt_slice = info["gt_lab"][:, :, slice_idx]
#                 pr_slice = info["pr_lab"][:, :, slice_idx]

#                 fig, axes = plt.subplots(1, 3, figsize=(15, 5))
#                 axes[0].imshow(raw_slice.T, cmap="gray", origin="lower")
#                 axes[0].set_title(f"{organ} — Raw")
#                 axes[0].axis("off")

#                 axes[1].imshow(raw_slice.T, cmap="gray", origin="lower")
#                 axes[1].imshow(gt_slice.T, cmap=info["gt_cmap"], origin="lower", vmin=0, vmax=info["n_parts"])
#                 axes[1].set_title("Ground Truth (parts)")
#                 axes[1].axis("off")

#                 axes[2].imshow(raw_slice.T, cmap="gray", origin="lower")
#                 axes[2].imshow(pr_slice.T, cmap=info["pr_cmap"], origin="lower", vmin=0, vmax=info["n_parts"])
#                 axes[2].set_title("Prediction (parts)")
#                 axes[2].axis("off")

#                 # metrics text under figure (from CSV averages if available)
#                 m = info["metrics"]
#                 met_text = f"Dice: {m['dice']:.4f}    IoU: {m['iou']:.4f}    HD95: {m['hd95'] if (not np.isnan(m['hd95'])) else 'nan'}"
#                 fig.text(0.5, 0.01, met_text, ha='center', fontsize=11)

#                 display(fig)
#                 plt.close(fig)
#         return handler

#     handler = make_handler(organ, slider, out)
#     slider.observe(handler, names='value')
#     # initial render
#     handler({'new': slider.value})
#     ui_widgets.append(widgets.VBox([slider, out]))

# # Show them stacked
# display(widgets.VBox(ui_widgets))

